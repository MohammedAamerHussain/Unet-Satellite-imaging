{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoNKdi54wrGC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqYYl22g6AXB",
        "outputId": "63688737-f2e4-48b6-f3de-a2711a43fe92"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "def unet_model(n_classes=5, im_sz=160, n_channels=8, n_filters_start=32, growth_factor=2, upconv=True,\n",
        "               class_weights=[0.2, 0.3, 0.1, 0.1, 0.3]):\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input((im_sz, im_sz, n_channels))\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    conv4 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up6 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4])\n",
        "    else:\n",
        "        up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4])\n",
        "    conv6 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6), conv3])\n",
        "    else:\n",
        "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3])\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
        "    else:\n",
        "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
        "    else:\n",
        "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    def weighted_binary_crossentropy(y_true, y_pred):\n",
        "        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
        "        return K.sum(class_loglosses * K.constant(class_weights))\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = unet_model()\n",
        "    print(model.summary())\n",
        "    plot_model(model, to_file='unet_model.png', show_shapes=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_rand_patch(img, mask, sz=160):\n",
        "    \"\"\"\n",
        "    :param img: ndarray with shape (x_sz, y_sz, num_channels)\n",
        "    :param mask: binary ndarray with shape (x_sz, y_sz, num_classes)\n",
        "    :param sz: size of random patch\n",
        "    :return: patch with shape (sz, sz, num_channels)\n",
        "    \"\"\"\n",
        "    assert len(img.shape) == 3 and img.shape[0] > sz and img.shape[1] > sz and img.shape[0:2] == mask.shape[0:2]\n",
        "    xc = random.randint(0, img.shape[0] - sz)\n",
        "    yc = random.randint(0, img.shape[1] - sz)\n",
        "    patch_img = img[xc:(xc + sz), yc:(yc + sz)]\n",
        "    patch_mask = mask[xc:(xc + sz), yc:(yc + sz)]\n",
        "    return patch_img, patch_mask\n",
        "\n",
        "\n",
        "def get_patches(x_dict, y_dict, n_patches, sz=160):\n",
        "    x = list()\n",
        "    y = list()\n",
        "    total_patches = 0\n",
        "    while total_patches < n_patches:\n",
        "        img_id = random.sample(x_dict.keys(), 1)[0]\n",
        "        img = x_dict[img_id]\n",
        "        mask = y_dict[img_id]\n",
        "        img_patch, mask_patch = get_rand_patch(img, mask, sz)\n",
        "        x.append(img_patch)\n",
        "        y.append(mask_patch)\n",
        "        total_patches += 1\n",
        "    print('Generated {} patches'.format(total_patches))\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os.path\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "def normalize(img):\n",
        "    min = img.min()\n",
        "    max = img.max()\n",
        "    x = 2.0 * (img - min) / (max - min) - 1.0\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "N_BANDS = 8\n",
        "N_CLASSES = 5  # buildings, roads, trees, crops and water\n",
        "CLASS_WEIGHTS = [0.2, 0.3, 0.1, 0.1, 0.3]\n",
        "N_EPOCHS = 100\n",
        "UPCONV = True\n",
        "PATCH_SZ = 160   # should divide by 16\n",
        "BATCH_SIZE = 100\n",
        "TRAIN_SZ = 4000  # train size\n",
        "VAL_SZ = 1000    # validation size\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    return unet_model(N_CLASSES, PATCH_SZ, n_channels=N_BANDS, upconv=UPCONV, class_weights=CLASS_WEIGHTS)\n",
        "\n",
        "\n",
        "weights_path = 'weights'\n",
        "if not os.path.exists(weights_path):\n",
        "    os.makedirs(weights_path)\n",
        "weights_path += '/unet_weights.hdf5'\n",
        "\n",
        "trainIds = [str(i).zfill(2) for i in range(1, 25)]  # all availiable ids: from \"01\" to \"24\"\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    X_DICT_TRAIN = dict()\n",
        "    Y_DICT_TRAIN = dict()\n",
        "    X_DICT_VALIDATION = dict()\n",
        "    Y_DICT_VALIDATION = dict()\n",
        "\n",
        "    print('Reading images')\n",
        "    for img_id in trainIds:\n",
        "        img_m = normalize(tiff.imread('/content/drive/MyDrive/SIS/data/mband/{}.tif'.format(img_id)).transpose([1, 2, 0]))\n",
        "        mask = tiff.imread('/content/drive/MyDrive/SIS/data/gt_mband/{}.tif'.format(img_id)).transpose([1, 2, 0]) / 255\n",
        "        train_xsz = int(3/4 * img_m.shape[0])  # use 75% of image as train and 25% for validation\n",
        "        X_DICT_TRAIN[img_id] = img_m[:train_xsz, :, :]\n",
        "        Y_DICT_TRAIN[img_id] = mask[:train_xsz, :, :]\n",
        "        X_DICT_VALIDATION[img_id] = img_m[train_xsz:, :, :]\n",
        "        Y_DICT_VALIDATION[img_id] = mask[train_xsz:, :, :]\n",
        "        print(img_id + ' read')\n",
        "    print('Images were read')\n",
        "\n",
        "    def train_net():\n",
        "        print(\"start train net\")\n",
        "        x_train, y_train = get_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=TRAIN_SZ, sz=PATCH_SZ)\n",
        "        x_val, y_val = get_patches(X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)\n",
        "        model = get_model()\n",
        "        if os.path.isfile(weights_path):\n",
        "            model.load_weights(weights_path)\n",
        "        model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True)\n",
        "        csv_logger = CSVLogger('log_unet.csv', append=True, separator=';')\n",
        "        tensorboard = TensorBoard(log_dir='./tensorboard_unet/', write_graph=True, write_images=True)\n",
        "        model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "                  verbose=2, shuffle=True,\n",
        "                  callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "                  validation_data=(x_val, y_val))\n",
        "        return model\n",
        "\n",
        "    train_net()\n",
        "\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "\n",
        "#from train_unet import weights_path, get_model, normalize, PATCH_SZ, N_CLASSES\n",
        "\n",
        "\n",
        "def predict(x, model, patch_sz=160, n_classes=5):\n",
        "    img_height = x.shape[0]\n",
        "    img_width = x.shape[1]\n",
        "    n_channels = x.shape[2]\n",
        "    # make extended img so that it contains integer number of patches\n",
        "    npatches_vertical = math.ceil(img_height / patch_sz)\n",
        "    npatches_horizontal = math.ceil(img_width / patch_sz)\n",
        "    extended_height = patch_sz * npatches_vertical\n",
        "    extended_width = patch_sz * npatches_horizontal\n",
        "    ext_x = np.zeros(shape=(extended_height, extended_width, n_channels), dtype=np.float32)\n",
        "    # fill extended image with mirrors:\n",
        "    ext_x[:img_height, :img_width, :] = x\n",
        "    for i in range(img_height, extended_height):\n",
        "        ext_x[i, :, :] = ext_x[2 * img_height - i - 1, :, :]\n",
        "    for j in range(img_width, extended_width):\n",
        "        ext_x[:, j, :] = ext_x[:, 2 * img_width - j - 1, :]\n",
        "\n",
        "    # now we assemble all patches in one array\n",
        "    patches_list = []\n",
        "    for i in range(0, npatches_vertical):\n",
        "        for j in range(0, npatches_horizontal):\n",
        "            x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "            y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "            patches_list.append(ext_x[x0:x1, y0:y1, :])\n",
        "    # model.predict() needs numpy array rather than a list\n",
        "    patches_array = np.asarray(patches_list)\n",
        "    # predictions:\n",
        "    patches_predict = model.predict(patches_array, batch_size=4)\n",
        "    prediction = np.zeros(shape=(extended_height, extended_width, n_classes), dtype=np.float32)\n",
        "    for k in range(patches_predict.shape[0]):\n",
        "        i = k // npatches_horizontal\n",
        "        j = k % npatches_vertical\n",
        "        x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "        y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "        prediction[x0:x1, y0:y1, :] = patches_predict[k, :, :, :]\n",
        "    return prediction[:img_height, :img_width, :]\n",
        "\n",
        "\n",
        "def picture_from_mask(mask, threshold=0):\n",
        "    colors = {\n",
        "        0: [150, 150, 150],  # Buildings\n",
        "        1: [223, 194, 125],  # Roads & Tracks\n",
        "        2: [27, 120, 55],    # Trees\n",
        "        3: [166, 219, 160],  # Crops\n",
        "        4: [116, 173, 209]   # Water\n",
        "    }\n",
        "    z_order = {\n",
        "        1: 3,\n",
        "        2: 4,\n",
        "        3: 0,\n",
        "        4: 1,\n",
        "        5: 2\n",
        "    }\n",
        "    pict = 255*np.ones(shape=(3, mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
        "    for i in range(1, 6):\n",
        "        cl = z_order[i]\n",
        "        for ch in range(3):\n",
        "            pict[ch,:,:][mask[cl,:,:] > threshold] = colors[cl][ch]\n",
        "    return pict\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = get_model()\n",
        "    model.load_weights(weights_path)\n",
        "    test_id = 'test'\n",
        "    img = normalize(tiff.imread('/content/drive/MyDrive/SIS/data/mband/{}.tif'.format(test_id)).transpose([1,2,0]))   # make channels last\n",
        "    mask = predict(img, model, patch_sz=PATCH_SZ, n_classes=N_CLASSES).transpose([2,0,1])  # make channels first\n",
        "    map = picture_from_mask(mask, 0.5)\n",
        "\n",
        "    tiff.imsave('result.tif', (255*mask).astype('uint8'))\n",
        "    tiff.imsave('map.tif', map)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 8) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 160, 160, 32) 2336        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 160, 160, 32) 9248        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 80, 80, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 80, 80, 64)   18496       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 80, 80, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 40, 40, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 40, 40, 128)  73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  147584      conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 20, 20, 128)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 20, 20, 256)  295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 20, 20, 256)  590080      conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 10, 10, 256)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 10, 10, 512)  1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 10, 10, 512)  2359808     conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 20, 20, 256)  524544      conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 20, 512)  0           conv2d_transpose[0][0]           \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 20, 20, 256)  1179904     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 20, 20, 256)  590080      conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 40, 40, 128)  131200      conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 40, 40, 256)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 40, 40, 128)  295040      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 40, 40, 128)  147584      conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 80, 80, 64)   32832       conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 80, 80, 128)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 80, 80, 64)   73792       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 80, 80, 64)   36928       conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 160, 160, 32) 8224        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 160, 160, 64) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 160, 160, 32) 18464       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 160, 160, 32) 9248        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 160, 160, 5)  165         conv2d_17[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 7,761,669\n",
            "Trainable params: 7,761,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Reading images\n",
            "01 read\n",
            "02 read\n",
            "03 read\n",
            "04 read\n",
            "05 read\n",
            "06 read\n",
            "07 read\n",
            "08 read\n",
            "09 read\n",
            "10 read\n",
            "11 read\n",
            "12 read\n",
            "13 read\n",
            "14 read\n",
            "15 read\n",
            "16 read\n",
            "17 read\n",
            "18 read\n",
            "19 read\n",
            "20 read\n",
            "21 read\n",
            "22 read\n",
            "23 read\n",
            "24 read\n",
            "Images were read\n",
            "start train net\n",
            "Generated 4000 patches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "gr0vKeXhX2h3",
        "outputId": "7b88f49d-39eb-4915-bbc9-61cb75d6c45d"
      },
      "source": [
        "#from unet_model import *\n",
        "#from gen_patches import *\n",
        "\n",
        "import os.path\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "def normalize(img):\n",
        "    min = img.min()\n",
        "    max = img.max()\n",
        "    x = 2.0 * (img - min) / (max - min) - 1.0\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "N_BANDS = 8\n",
        "N_CLASSES = 5  # buildings, roads, trees, crops and water\n",
        "CLASS_WEIGHTS = [0.2, 0.3, 0.1, 0.1, 0.3]\n",
        "N_EPOCHS = 100\n",
        "UPCONV = True\n",
        "PATCH_SZ = 160   # should divide by 16\n",
        "BATCH_SIZE = 100\n",
        "TRAIN_SZ = 4000  # train size\n",
        "VAL_SZ = 1000    # validation size\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    return unet_model(N_CLASSES, PATCH_SZ, n_channels=N_BANDS, upconv=UPCONV, class_weights=CLASS_WEIGHTS)\n",
        "\n",
        "\n",
        "weights_path = 'weights'\n",
        "if not os.path.exists(weights_path):\n",
        "    os.makedirs(weights_path)\n",
        "weights_path += '/unet_weights.hdf5'\n",
        "\n",
        "trainIds = [str(i).zfill(2) for i in range(1, 25)]  # all availiable ids: from \"01\" to \"24\"\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    X_DICT_TRAIN = dict()\n",
        "    Y_DICT_TRAIN = dict()\n",
        "    X_DICT_VALIDATION = dict()\n",
        "    Y_DICT_VALIDATION = dict()\n",
        "\n",
        "    print('Reading images')\n",
        "    for img_id in trainIds:\n",
        "        img_m = normalize(tiff.imread('/content/drive/MyDrive/SIS/data/mband/{}.tif'.format(img_id)).transpose([1, 2, 0]))\n",
        "        mask = tiff.imread('/content/drive/MyDrive/SIS/data/gt_mband/{}.tif'.format(img_id)).transpose([1, 2, 0]) / 255\n",
        "        train_xsz = int(3/4 * img_m.shape[0])  # use 75% of image as train and 25% for validation\n",
        "        X_DICT_TRAIN[img_id] = img_m[:train_xsz, :, :]\n",
        "        Y_DICT_TRAIN[img_id] = mask[:train_xsz, :, :]\n",
        "        X_DICT_VALIDATION[img_id] = img_m[train_xsz:, :, :]\n",
        "        Y_DICT_VALIDATION[img_id] = mask[train_xsz:, :, :]\n",
        "        print(img_id + ' read')\n",
        "    print('Images were read')\n",
        "\n",
        "    def train_net():\n",
        "        print(\"start train net\")\n",
        "        x_train, y_train = get_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=TRAIN_SZ, sz=PATCH_SZ)\n",
        "        x_val, y_val = get_patches(X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)\n",
        "        model = get_model()\n",
        "        if os.path.isfile(weights_path):\n",
        "            model.load_weights(weights_path)\n",
        "        model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True)\n",
        "        csv_logger = CSVLogger('log_unet.csv', append=True, separator=';')\n",
        "        tensorboard = TensorBoard(log_dir='./tensorboard_unet/', write_graph=True, write_images=True)\n",
        "        model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "                  verbose=2, shuffle=True,\n",
        "                  callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "                  validation_data=(x_val, y_val))\n",
        "        return model\n",
        "\n",
        "    train_net()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading images\n",
            "01 read\n",
            "02 read\n",
            "03 read\n",
            "04 read\n",
            "05 read\n",
            "06 read\n",
            "07 read\n",
            "08 read\n",
            "09 read\n",
            "10 read\n",
            "11 read\n",
            "12 read\n",
            "13 read\n",
            "14 read\n",
            "15 read\n",
            "16 read\n",
            "17 read\n",
            "18 read\n",
            "19 read\n",
            "20 read\n",
            "21 read\n",
            "22 read\n",
            "23 read\n",
            "24 read\n",
            "Images were read\n",
            "start train net\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5874ba9d88eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-5874ba9d88eb>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start train net\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_DICT_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_DICT_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_SZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATCH_SZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_DICT_VALIDATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_DICT_VALIDATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL_SZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATCH_SZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_patches' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frl3MzBrZX58",
        "outputId": "6fb4c698-f46d-4a6b-fe27-bcc1a2c8d140"
      },
      "source": [
        "!ls /content/drive/MyDrive/SIS/data/gt_mband/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04.tif\t06.tif\t07.tif\t10.tif\t12.tif\t13.tif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "43giVKdpX2rt",
        "outputId": "78222c9a-878a-4ac9-8d2d-343517faad08"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "\n",
        "#from train_unet import weights_path, get_model, normalize, PATCH_SZ, N_CLASSES\n",
        "\n",
        "\n",
        "def predict(x, model, patch_sz=160, n_classes=5):\n",
        "    img_height = x.shape[0]\n",
        "    img_width = x.shape[1]\n",
        "    n_channels = x.shape[2]\n",
        "    # make extended img so that it contains integer number of patches\n",
        "    npatches_vertical = math.ceil(img_height / patch_sz)\n",
        "    npatches_horizontal = math.ceil(img_width / patch_sz)\n",
        "    extended_height = patch_sz * npatches_vertical\n",
        "    extended_width = patch_sz * npatches_horizontal\n",
        "    ext_x = np.zeros(shape=(extended_height, extended_width, n_channels), dtype=np.float32)\n",
        "    # fill extended image with mirrors:\n",
        "    ext_x[:img_height, :img_width, :] = x\n",
        "    for i in range(img_height, extended_height):\n",
        "        ext_x[i, :, :] = ext_x[2 * img_height - i - 1, :, :]\n",
        "    for j in range(img_width, extended_width):\n",
        "        ext_x[:, j, :] = ext_x[:, 2 * img_width - j - 1, :]\n",
        "\n",
        "    # now we assemble all patches in one array\n",
        "    patches_list = []\n",
        "    for i in range(0, npatches_vertical):\n",
        "        for j in range(0, npatches_horizontal):\n",
        "            x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "            y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "            patches_list.append(ext_x[x0:x1, y0:y1, :])\n",
        "    # model.predict() needs numpy array rather than a list\n",
        "    patches_array = np.asarray(patches_list)\n",
        "    # predictions:\n",
        "    patches_predict = model.predict(patches_array, batch_size=4)\n",
        "    prediction = np.zeros(shape=(extended_height, extended_width, n_classes), dtype=np.float32)\n",
        "    for k in range(patches_predict.shape[0]):\n",
        "        i = k // npatches_horizontal\n",
        "        j = k % npatches_vertical\n",
        "        x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "        y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "        prediction[x0:x1, y0:y1, :] = patches_predict[k, :, :, :]\n",
        "    return prediction[:img_height, :img_width, :]\n",
        "\n",
        "\n",
        "def picture_from_mask(mask, threshold=0):\n",
        "    colors = {\n",
        "        0: [150, 150, 150],  # Buildings\n",
        "        1: [223, 194, 125],  # Roads & Tracks\n",
        "        2: [27, 120, 55],    # Trees\n",
        "        3: [166, 219, 160],  # Crops\n",
        "        4: [116, 173, 209]   # Water\n",
        "    }\n",
        "    z_order = {\n",
        "        1: 3,\n",
        "        2: 4,\n",
        "        3: 0,\n",
        "        4: 1,\n",
        "        5: 2\n",
        "    }\n",
        "    pict = 255*np.ones(shape=(3, mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
        "    for i in range(1, 6):\n",
        "        cl = z_order[i]\n",
        "        for ch in range(3):\n",
        "            pict[ch,:,:][mask[cl,:,:] > threshold] = colors[cl][ch]\n",
        "    return pict\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = get_model()\n",
        "    model.load_weights(weights_path)\n",
        "    test_id = 'test'\n",
        "    img = normalize(tiff.imread('/content/drive/MyDrive/SIS/data/mband/{}.tif'.format(test_id)).transpose([1,2,0]))   # make channels last\n",
        "    mask = predict(img, model, patch_sz=PATCH_SZ, n_classes=N_CLASSES).transpose([2,0,1])  # make channels first\n",
        "    map = picture_from_mask(mask, 0.5)\n",
        "\n",
        "    tiff.imsave('result.tif', (255*mask).astype('uint8'))\n",
        "    tiff.imsave('map.tif', map)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2df43cace205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQpeBVV5z7A1"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_rand_patch(img, mask, sz=160):\n",
        "    \"\"\"\n",
        "    :param img: ndarray with shape (x_sz, y_sz, num_channels)\n",
        "    :param mask: binary ndarray with shape (x_sz, y_sz, num_classes)\n",
        "    :param sz: size of random patch\n",
        "    :return: patch with shape (sz, sz, num_channels)\n",
        "    \"\"\"\n",
        "    assert len(img.shape) == 3 and img.shape[0] > sz and img.shape[1] > sz and img.shape[0:2] == mask.shape[0:2]\n",
        "    xc = random.randint(0, img.shape[0] - sz)\n",
        "    yc = random.randint(0, img.shape[1] - sz)\n",
        "    patch_img = img[xc:(xc + sz), yc:(yc + sz)]\n",
        "    patch_mask = mask[xc:(xc + sz), yc:(yc + sz)]\n",
        "    return patch_img, patch_mask\n",
        "\n",
        "\n",
        "def get_patches(x_dict, y_dict, n_patches, sz=160):\n",
        "    x = list()\n",
        "    y = list()\n",
        "    total_patches = 0\n",
        "    while total_patches < n_patches:\n",
        "        img_id = random.sample(x_dict.keys(), 1)[0]\n",
        "        img = x_dict[img_id]\n",
        "        mask = y_dict[img_id]\n",
        "        img_patch, mask_patch = get_rand_patch(img, mask, sz)\n",
        "        x.append(img_patch)\n",
        "        y.append(mask_patch)\n",
        "        total_patches += 1\n",
        "    print('Generated {} patches'.format(total_patches))\n",
        "    return np.array(x), np.array(y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXJm0yWTz7KW",
        "outputId": "3facf2db-c3ee-4ccc-a3b7-4d16d441cedd"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFlPeGaA0JFu"
      },
      "source": [
        "!mkdir -p AML/SIS"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzXZXiRwSYTw",
        "outputId": "d5fdaf2c-9944-4650-a252-28904ab883df"
      },
      "source": [
        "!ls  /content/drive/MyDrive/SIS/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gt_mband  mband\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M4J2aCRXU1-",
        "outputId": "36eaf9e5-3ba3-4f56-e7fd-faf5f1bc655f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7PpX2I_YwuI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}